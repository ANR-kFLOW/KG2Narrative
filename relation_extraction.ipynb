{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-msVVZZ3Lmg",
    "outputId": "2c63d5b6-7c1f-4cab-af95-b5e4fba4e9d8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.26.1)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.9/dist-packages (0.4.0)\n",
      "Requirement already satisfied: rouge_score in /usr/local/lib/python3.9/dist-packages (0.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.4.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.3.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.10.1)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.15.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (1.1.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (8.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (3.1.0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "! pip install transformers evaluate rouge_score\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sklearn import preprocessing\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def preprocess_data(data): #this is used to process the data for the tokenizer\n",
    "    context = data['context'].to_list() #First convert to a list\n",
    "    text_encodings = tokenizer(context, truncation=True, padding=True)\n",
    "\n",
    "    triplets = data['triplets'].to_list()\n",
    "    label_encodings = tokenizer(triplets, truncation=True, padding=True)\n",
    "    #new_data ={\"input_ids\":model_inputs[\"input_ids\"], \"labels\": labels[\"input_ids\"]}\n",
    "\n",
    "    return text_encodings, label_encodings\n",
    "\n",
    "class RebelDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels['input_ids'])\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "RgqGVTEr3Lmj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_checkpoint = \"Babelscape/rebel-large\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "f8ceSbln3Lmo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = 1\n",
    "data = pd.read_csv('rebel_format_v2.csv')\n",
    "train_data, val_data = train_test_split(data, test_size=0.1, random_state=seed)\n",
    "del data\n",
    "\n",
    "train_encodings, train_labels = preprocess_data(train_data)\n",
    "train_data = RebelDataset(train_encodings, train_labels)\n",
    "val_encodings, val_labels = preprocess_data(val_data)\n",
    "val_data = RebelDataset(val_encodings, val_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-faro-relations\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=0.000025,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.1,\n",
    "    save_total_limit=1,\n",
    "    #save_steps=300,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='F1 relations',\n",
    "    num_train_epochs=7,\n",
    "    predict_with_generate=True,\n",
    "    fp16 = True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric = load_metric(\"rouge\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_rouge(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip()))\n",
    "                      for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) \n",
    "                      for label in decoded_labels]\n",
    "    \n",
    "    # Compute ROUGE scores\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels,\n",
    "                            use_stemmer=True)\n",
    "\n",
    "    # Extract ROUGE f1 scores\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length to metrics\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id)\n",
    "                      for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "def check_format(data):\n",
    "    #This is used to check if the extraction worked\n",
    "\n",
    "    if len(data) != 3:\n",
    "      return ['wrong', 'wrong', 'wrong']\n",
    "    else:\n",
    "      return data\n",
    "\n",
    "def compute_f1(eval_pred):\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = tokenizer.batch_decode(predictions, skip_special_tokens=False)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=False)\n",
    "\n",
    "    pattern = r'>([^<]+)'\n",
    "    predictions = [check_format(re.findall(pattern, instance)) for instance in predictions]\n",
    "    try:\n",
    "      predictions = pd.DataFrame(predictions, columns =['Subject', 'Object', 'Relation'])\n",
    "    except:\n",
    "      print(\"Something went wrong with extracting and creating predictions dataframe\")\n",
    "\n",
    "    try:\n",
    "      labels = [check_format(re.findall(pattern, instance)) for instance in labels]\n",
    "      labels = pd.DataFrame(labels, columns =['Subject', 'Object', 'Relation'])\n",
    "    except:\n",
    "      print(\"Something went wrong with extracting and creating label dataframe\")\n",
    "    #F1 can only be computed on integer labels, so we need to encode them\n",
    "    try:\n",
    "        le_subject= preprocessing.LabelEncoder()\n",
    "        le_subject.fit(predictions['Subject']) #Learn the encodings on the predictions for subject\n",
    "        le_subject_dict = dict(zip(le_subject.classes_, le_subject.transform(le_subject.classes_)))\n",
    "    except:\n",
    "        print(\"Something went wrong when calculating subject encodings\")\n",
    "    del le_subject\n",
    "\n",
    "    #Encode in the same way, if it doesn't exist set to non existent number\n",
    "    try:\n",
    "        predictions['Subject'] = predictions['Subject'].apply(lambda x: le_subject_dict.get(x, 999999999))\n",
    "        labels['Subject'] = labels['Subject'].apply(lambda x: le_subject_dict.get(x, 999999999))\n",
    "    except:\n",
    "        print(\"Something went wrong when applying the subject labels\")\n",
    "    \n",
    "    try:\n",
    "        metrics['F1 Subject'] = f1_metric.compute(predictions=predictions['Subject'].to_list(), references=labels['Subject'].to_list(), average='macro')['f1']\n",
    "    except:\n",
    "        print(\"Something went wrong when computing the f1 score for subject\")\n",
    "    del le_subject_dict\n",
    "\n",
    "    try:\n",
    "        le_object= preprocessing.LabelEncoder()\n",
    "        le_object.fit(predictions['Object']) #Learn the encodings on the predictions for object\n",
    "        le_object_dict = dict(zip(le_object.classes_, le_object.transform(le_object.classes_)))\n",
    "    except:\n",
    "        print(\"Something went wrong when calculating object encodings\")\n",
    "    del le_object\n",
    "\n",
    "    try:\n",
    "        predictions['Object'] = predictions['Object'].apply(lambda x: le_object_dict.get(x, 999999999))\n",
    "        labels['Object'] = labels['Object'].apply(lambda x: le_object_dict.get(x, 999999999))\n",
    "    except:\n",
    "        print(\"Something went wrong when applying Object encodings\")\n",
    "    \n",
    "    try:\n",
    "        metrics['F1 Object'] = f1_metric.compute(predictions=predictions['Object'].to_list(), references=labels['Object'].to_list(), average='macro')['f1']\n",
    "    except:\n",
    "        print(\"Something went wrong when computing F1 scores for object\")\n",
    "    del le_object_dict\n",
    "\n",
    "    try:\n",
    "        le_relations = preprocessing.LabelEncoder() #since there are a fixed number of classes no dict needs to be created\n",
    "        le_relations.fit(labels['Relation']) #Learn the representation on the predictions for relations\n",
    "        le_relations_dict = dict(zip(le_relations.classes_, le_relations.transform(le_relations.classes_)))\n",
    "        #del le_relations\n",
    "    except:\n",
    "        print(\"Something went wrong when calculating the relation encodings\")\n",
    "\n",
    "    try:\n",
    "        labels['Relation'] = labels['Relation'].apply(lambda x: le_relations_dict.get(x, 999999999))\n",
    "        predictions['Relation'] = predictions['Relation'].apply(lambda x: le_relations_dict.get(x, 999999999))\n",
    "\n",
    "        #print(labels['Relation'])\n",
    "        #print(predictions['Relation'])\n",
    "    except:\n",
    "        print(\"Something went wrong when applying relation encodings\")\n",
    "    \n",
    "    try:\n",
    "        f1 = f1_metric.compute(predictions=predictions['Relation'].to_list(), references=labels['Relation'].to_list(), average= None)['f1']\n",
    "        metrics['F1 relations'] = f1_metric.compute(predictions=predictions['Relation'].to_list(), references=labels['Relation'].to_list(), average= 'macro')['f1']\n",
    "    except:\n",
    "        print(\"Something went wrong with computing f1 for relations\")\n",
    "    try:\n",
    "        \n",
    "        for i in range(len(le_relations.classes_)):\n",
    "            metrics[f'F1 {le_relations.classes_[i].strip()}'] = f1[i]\n",
    "    except:\n",
    "        print(\"something went wrong when assigning relation scores\")\n",
    "\n",
    "    return metrics\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics= compute_f1\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.save_model(\"finetuned_rebel\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"rebel_finetuned\", 'zip', \"finetuned_rebel\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.unpack_archive('/content/drive/MyDrive/rebel_finetuned.zip', '/content/rebel_finetuned', 'zip')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"rebel_finetuned\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('Babelscape/rebel-large')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = [\"because the machine is old, it is unreliable\", \"many people have died in the storm\", \"now the preparation is complete, we can start again\",\n",
    "        \"the restrictions made sure less people got infected\", \"I am running everyday because i want to run a marathon\", \"the elevator is fixed, so i can go up again\",\n",
    "        \"There was a traffic jam, so i was late\", \"I broke my leg, so I can't run the marathon\", \"Since I failed the exam, I can't graduate\",\n",
    "        \"I did some shopping, because i want to cook later\", \"I shouldn't have said that, I did not mean that\", \"I wanted to say that\", \"I am planning on doing that later\",\n",
    "        \"I intend on doing that\"]\n",
    "encoding = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# forward pass\n",
    "outputs = model.generate(**encoding, do_sample=True)\n",
    "decoded_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(decoded_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}