{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def preprocess_data(data): #this is used to process the data for the tokenizer\n",
    "    context = data['context'].to_list() #First convert to a list\n",
    "    text_encodings = tokenizer(context, truncation=True, padding=True)\n",
    "\n",
    "    triplets = data['triplets'].to_list()\n",
    "    label_encodings = tokenizer(triplets, truncation=True, padding=True)\n",
    "    #new_data ={\"input_ids\":model_inputs[\"input_ids\"], \"labels\": labels[\"input_ids\"]}\n",
    "\n",
    "    return text_encodings, label_encodings\n",
    "\n",
    "class RebelDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels['input_ids'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\mike-/.cache\\huggingface\\hub\\models--Babelscape--rebel-large\\snapshots\\d24237e8ab9c1ad2cbdf53fd54b0d7cda1da8018\\config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"Babelscape/rebel-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 200,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"relation_extraction\": {\n",
      "      \"length_penalty\": 0.0,\n",
      "      \"max_length\": 256,\n",
      "      \"min_length\": 12,\n",
      "      \"no_repeat_ngram_size\": 0,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\mike-/.cache\\huggingface\\hub\\models--Babelscape--rebel-large\\snapshots\\d24237e8ab9c1ad2cbdf53fd54b0d7cda1da8018\\pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 200,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at Babelscape/rebel-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n",
      "loading file vocab.json from cache at C:\\Users\\mike-/.cache\\huggingface\\hub\\models--Babelscape--rebel-large\\snapshots\\d24237e8ab9c1ad2cbdf53fd54b0d7cda1da8018\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\mike-/.cache\\huggingface\\hub\\models--Babelscape--rebel-large\\snapshots\\d24237e8ab9c1ad2cbdf53fd54b0d7cda1da8018\\merges.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\mike-/.cache\\huggingface\\hub\\models--Babelscape--rebel-large\\snapshots\\d24237e8ab9c1ad2cbdf53fd54b0d7cda1da8018\\tokenizer.json\n",
      "loading file added_tokens.json from cache at C:\\Users\\mike-/.cache\\huggingface\\hub\\models--Babelscape--rebel-large\\snapshots\\d24237e8ab9c1ad2cbdf53fd54b0d7cda1da8018\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\mike-/.cache\\huggingface\\hub\\models--Babelscape--rebel-large\\snapshots\\d24237e8ab9c1ad2cbdf53fd54b0d7cda1da8018\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\mike-/.cache\\huggingface\\hub\\models--Babelscape--rebel-large\\snapshots\\d24237e8ab9c1ad2cbdf53fd54b0d7cda1da8018\\tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"Babelscape/rebel-large\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "seed = 1\n",
    "data = pd.read_csv('Data/rebel/rebel_format.csv')\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=seed)\n",
    "del data\n",
    "\n",
    "train_encodings, train_labels = preprocess_data(train_data.head(100))\n",
    "train_data = RebelDataset(train_encodings, train_labels)\n",
    "val_encodings, val_labels = preprocess_data(val_data.head(10))\n",
    "val_data = RebelDataset(val_encodings, val_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-faro-relations\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=0.000025,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.1,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=7,\n",
    "    predict_with_generate=True, #Maybe switch to false?\n",
    "    push_to_hub=False,\n",
    ")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\mike-\\documents\\vu\\eurecom\\venv\\lib\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\mike-\\documents\\vu\\eurecom\\venv\\lib\\site-packages (from rouge_score) (1.24.2)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\mike-\\documents\\vu\\eurecom\\venv\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\mike-\\documents\\vu\\eurecom\\venv\\lib\\site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mike-\\documents\\vu\\eurecom\\venv\\lib\\site-packages (from nltk->rouge_score) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mike-\\documents\\vu\\eurecom\\venv\\lib\\site-packages (from nltk->rouge_score) (4.65.0)\n",
      "Requirement already satisfied: click in c:\\users\\mike-\\documents\\vu\\eurecom\\venv\\lib\\site-packages (from nltk->rouge_score) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mike-\\documents\\vu\\eurecom\\venv\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py): started\n",
      "  Building wheel for rouge-score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=45fa49797212b75b8166f320d047dfbc759a3393dd2cddd8b7a33577286791d4\n",
      "  Stored in directory: c:\\users\\mike-\\appdata\\local\\pip\\cache\\wheels\\24\\55\\6f\\ebfc4cb176d1c9665da4e306e1705496206d08215c1acd9dde\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: absl-py, rouge-score\n",
      "Successfully installed absl-py-1.4.0 rouge-score-0.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\mike-\\Documents\\VU\\Eurecom\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "def metrics_func(eval_arg):\n",
    "  preds, labels = eval_arg\n",
    "  rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "  return rouge_metric.compute(\n",
    "    predictions=preds,\n",
    "    references=labels\n",
    "  )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}