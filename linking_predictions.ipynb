{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Generate the event and article knowledge graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import ast\n",
    "from resources import *\n",
    "import re\n",
    "\n",
    "rnews = Namespace(\"http://iptc.org/std/rNews/2011-10-07#\")\n",
    "nif = Namespace(\"http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#\")\n",
    "faro = Namespace(\"https://purl.org/faro/\")\n",
    "sem = Namespace(\"http://semanticweb.cs.vu.nl/2009/11/sem/\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rnews = Namespace(\"http://iptc.org/std/rNews/2011-10-07#\")\n",
    "schema = Namespace(\"http://schema.org/\")\n",
    "\n",
    "faro_classes = {'cause': faro.causes, 'enable': faro.enables, 'intend': faro.intends_to_cause, 'prevent': faro.prevents} #dict of faro definitions\n",
    "sem_props = {'http://www.wikidata.org/prop/direct/P710': sem.hasActor,\n",
    "             'http://www.wikidata.org/prop/direct/P664': sem.hasActor,\n",
    "             'http://www.wikidata.org/prop/direct/P112': sem.hasActor,\n",
    "             'http://www.wikidata.org/prop/direct/P17': sem.hasPlace,\n",
    "             'http://www.wikidata.org/prop/direct/P276': sem.hasPlace,\n",
    "             'http://www.wikidata.org/prop/direct/P625': sem.hasPlace,\n",
    "             'http://www.wikidata.org/prop/direct/P131': sem.hasPlace,\n",
    "             'http://www.wikidata.org/prop/direct/P30': sem.hasPlace,\n",
    "             'http://www.wikidata.org/prop/direct/P585': sem.hasTime,\n",
    "             'http://www.wikidata.org/prop/direct/P580': sem.hasBeginTimeStamp,\n",
    "             'http://www.wikidata.org/prop/direct/P582': sem.hasEndTimeStamp,\n",
    "             'http://www.wikidata.org/prop/direct/P571': sem.hasTime,\n",
    "             'http://www.wikidata.org/prop/direct/P576': sem.hasTime,\n",
    "             'http://www.wikidata.org/prop/direct/P577': sem.hasTimeStamp,\n",
    "             'http://www.w3.org/2000/01/rdf-schema#label': 'what'}\n",
    "\n",
    "sem_classes = {sem.hasActor: sem.Actor,\n",
    "               sem.hasPlace: sem.Place,\n",
    "               sem.hasTime: sem.Time,\n",
    "               sem.hasBeginTimeStamp: sem.Time,\n",
    "               sem.hasEndTimeStamp: sem.Time,\n",
    "               sem.hasTimeStamp: sem.Time,\n",
    "               'what': sem.Event}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from resources import clean_text\n",
    "data = pd.read_csv('Data/ASRAEL_data_full.csv')\n",
    "data['Text'] = data['Text'].apply(clean_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when searching for event: http://www.wikidata.org/entity/Q100919128\n",
      "Error when searching for event: http://www.wikidata.org/entity/Q113945893\n",
      "Error when searching for event: http://www.wikidata.org/entity/Q105597606\n"
     ]
    }
   ],
   "source": [
    "#This converts the data into the right format, by removing uneccessary tokens in text and converting the wikidata link to text\n",
    "from resources import uri_validator\n",
    "graph = Graph()\n",
    "\n",
    "event_mapping = {} #here the wikidata event urls and their names are saved\n",
    "failed_events= [] #Events that can't be found e.g. owl:sameAs need to be removed\n",
    "\n",
    "sparql = SPARQLWrapper(\n",
    "    \"https://query.wikidata.org/sparql\"\n",
    ")\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "for event in data['Event'].unique().tolist():\n",
    "    event_ = f\"wd:{event.split('/')[-1]}\"\n",
    "\n",
    "    sparql.setQuery(\"\"\"\n",
    "    SELECT (?p as ?wiki_prop) (?o as ?result)\n",
    "    WHERE {{{\n",
    "\n",
    "        %s ?p ?temp.\n",
    "      ?temp rdfs:label ?o.\n",
    "      FILTER (lang(?o) = 'en') }\n",
    "      }\n",
    "\n",
    "      UNION\n",
    "\n",
    "      {\n",
    "       SELECT *\n",
    "       WHERE{\n",
    "        %s ?p ?o.\n",
    "         FILTER(lang(?o) = 'en' || lang(?o)='') }}\n",
    "     } \"\"\" % (event_, event_))\n",
    "\n",
    "    try:\n",
    "        result = sparql.queryAndConvert()\n",
    "        #event_name = ret['results']['bindings'][0]['item']['value']\n",
    "\n",
    "    except:\n",
    "        print(f\"Something went wrong when converting event: {event}\")\n",
    "\n",
    "    try:\n",
    "        event_data = pd.json_normalize(result[\"results\"][\"bindings\"])[['wiki_prop.value', 'result.value', 'result.datatype']]\n",
    "        event_data = event_data.rename(columns={\"wiki_prop.value\": \"property\", \"result.value\": \"value\", \"result.datatype\": \"datatype\"})\n",
    "        event_data = event_data.loc[event_data['property'].isin(sem_props.keys())].reset_index(drop=True) #Only keep the 4W attributes\n",
    "        event_data['property'] = event_data['property'].replace(sem_props)\n",
    "        event_name = event_data.loc[event_data['property'] == 'what']['value'].values[0] #This needs to be saved to map the wikidata urls to events\n",
    "        event_data = event_data[event_data.property != 'what'] #This row needs to be deleted for the loop\n",
    "        event_mapping[event] = event_name\n",
    "    except:\n",
    "        print(f\"Error when searching for event: {event}\")\n",
    "        failed_events.append(event)\n",
    "        continue\n",
    "\n",
    "    #event_uri = node_creation('', event_name, base_add='/event') #Generate the URI for the event\n",
    "    graph.add((URIRef(event), RDF.type, sem.Event)) #Create the event\n",
    "    graph.add((URIRef(event), RDF.value, Literal(event_name)))\n",
    "\n",
    "    for index, row in event_data.iterrows():\n",
    "        uri = node_creation('', row['value'], base_add='') #Generate the URI for the property\n",
    "        if uri_validator(uri) == False:\n",
    "            print(f\"Found issue, generated link is not an uri:\\n{uri}\")\n",
    "        graph.add((uri, RDF.type, sem_classes[row['property']])) #Create the node for the property, and lookup its class\n",
    "        if pd.isna(row['datatype']) == False: #It has a declared datatype\n",
    "            graph.add((uri, RDF.value, Literal(row['value'], datatype=row['datatype'])))\n",
    "        else:\n",
    "            graph.add((uri, RDF.value, Literal(row['value']))) #Add the value of the relation to the graph\n",
    "        graph.add((URIRef(event), row['property'], uri)) #Connect the event to the property\n",
    "\n",
    "graph.serialize('Data/graphs/final_generated/Event_graph_all.ttl', format='turtle')\n",
    "\n",
    "data= data[~data['Event'].isin(failed_events)] #remove the rows for which the event was not found\n",
    "#data['Event'] = data['Event'].map(event_mapping)\n",
    "#Check if this still is oke, it adds a list of events to the column event\n",
    "data = data.groupby(['URI','Identifier','Location', 'Time', 'Text']).agg({'Event': lambda x: list(x)}).reset_index(drop=False)\n",
    "data.to_csv('Data/dataset_final_generated/ASRAEL_data_full_converted.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1122 [00:00<?, ?it/s]C:\\Users\\mike-\\Documents\\VU\\Eurecom\\KG_mapping\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (200) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/1122 [00:11<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform predictions, execute cell below to combine predictions and generate the graph at once.\n",
    "import pandas as pd\n",
    "from rebel_finetuning_faro import make_predictions\n",
    "from nltk import tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('Data/dataset_final_generated/ASRAEL_data_full_converted.csv')\n",
    "total_uri = []\n",
    "total_identifier = []\n",
    "total_location = []\n",
    "total_time = []\n",
    "total_event = []\n",
    "total_sentence_num = []\n",
    "total_sentences = []\n",
    "total_subject = []\n",
    "total_relation = []\n",
    "total_object = []\n",
    "\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    sentences, predictions = make_predictions(tokenize.sent_tokenize(row['Text']), 'rebel_finetuned.pth')\n",
    "    for i, (sentence, prediction) in enumerate(zip(sentences, predictions)):\n",
    "\n",
    "        total_uri.append(row['URI'])\n",
    "        total_identifier.append(row['Identifier'])\n",
    "        total_location.append(row['Location'])\n",
    "        total_time.append(row['Time'])\n",
    "        total_event.append(row['Event'])\n",
    "        total_sentence_num.append(i)\n",
    "        total_sentences.append(sentence)\n",
    "        total_subject.append(prediction[0])\n",
    "        total_relation.append(prediction[1])\n",
    "        total_object.append(prediction[2])\n",
    "    break\n",
    "\n",
    "\n",
    "new_data = pd.DataFrame({'URI': total_uri, 'Identifier': total_identifier, 'Location': total_location, 'Time': total_time, 'Sentence_num': total_sentence_num, 'Sentence': total_sentences, 'Subject': total_subject, 'Relation': total_relation, 'Object': total_object, 'Event': total_event})\n",
    "\n",
    "new_data = new_data[~((new_data['Sentence'].str.len() < 25) & new_data['Sentence'].str.contains('/'))].reset_index(drop=True)\n",
    "\n",
    "new_data.to_csv('Data/final_generated/final_data_with_predictions.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19578/19578 [00:25<00:00, 754.16it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": "<Graph identifier=N6eaa17f7cbe443be835e69bcc063e464 (<class 'rdflib.graph.Graph'>)>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from nltk import tokenize\n",
    "\n",
    "graph = Graph()\n",
    "graph.parse('Data/graphs/final_generated/Event_graph_all.ttl')\n",
    "data = pd.read_csv('Data/final_data_with_predictions.csv')\n",
    "\n",
    "data_with_predictions = True #Set this to True if the cell above was executed\n",
    "\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "\n",
    "    if not row.isnull().values.any(): #If nan is present skip the row\n",
    "\n",
    "        graph.add((URIRef(row['URI']), RDF.type, rnews.Article)) #Add the URI as article\n",
    "\n",
    "        identifier_uri = node_creation('', row['Identifier'], base_add='/identifier')\n",
    "        graph.add((URIRef(row['URI']), rnews.identifier, URIRef(identifier_uri))) #Link the PublicID to the article\n",
    "        graph.add((URIRef(identifier_uri), RDF.value, Literal(row['Identifier'])))\n",
    "\n",
    "        location_uri = node_creation('', row['Location'], base_add='')\n",
    "        graph.add((URIRef(row['URI']), schema.contentLocation, URIRef(location_uri)))\n",
    "        graph.add((URIRef(location_uri), RDF.value, Literal(row['Location'])))\n",
    "        graph.add((URIRef(location_uri), RDF.type, schema.Place))\n",
    "\n",
    "        time_uri = node_creation('', row['Time'], base_add='')\n",
    "        graph.add((URIRef(row['URI']), schema.contentReferenceTime, URIRef(time_uri)))\n",
    "        graph.add((URIRef(time_uri), RDF.value, Literal(row['Time'])))\n",
    "        graph.add((URIRef(time_uri), RDF.type, schema.Time))\n",
    "\n",
    "        if data_with_predictions == False: #Make the predictions\n",
    "\n",
    "            from rebel_finetuning_faro import make_predictions\n",
    "\n",
    "            sentences, predictions = make_predictions(tokenize.sent_tokenize(row['Text']), 'rebel_finetuned.pth')\n",
    "            for sentence, prediction in zip(sentences, predictions):\n",
    "\n",
    "                if prediction[1] in faro_classes:\n",
    "                    sentence_uri = node_creation('', sentence, base_add='/sentence') #Generate the URI for the sentence\n",
    "                    graph.add((URIRef(row['URI']), nif.sentence, sentence_uri)) #Link the article to the sentence\n",
    "                    graph.add((sentence_uri, RDF.type, nif.Sentence)) #Make the sentence URI of class 'Sentence'\n",
    "                    graph.add((sentence_uri, RDF.value, Literal(sentence))) #Set the value of the URI equal to the sentence\n",
    "\n",
    "                    subject_uri = node_creation('', prediction[0] + str(sentence_uri), base_add='/subject') #Generate the URI for the subject, for now add the uri of sentence to make it unique\n",
    "                    graph.add((sentence_uri, faro.Relata, subject_uri)) #Add the subject to the sentence\n",
    "                    graph.add((subject_uri, RDF.value, Literal(prediction[0]))) #Set the value of the subject URI equal to the subject\n",
    "\n",
    "                    object_uri = node_creation('', prediction[2] + str(sentence_uri), base_add='/object') #Generate the URI for the object, for now add the uri of sentence to make it unique\n",
    "                    graph.add((sentence_uri, faro.Relata, object_uri)) #Add the object to the sentence\n",
    "                    graph.add((object_uri, RDF.value, Literal(prediction[2]))) #Set the value of the subject URI equal to the object\n",
    "\n",
    "                    graph.add((subject_uri, faro_classes[prediction[1]], object_uri)) #Add relation betwee NERs\n",
    "                else:\n",
    "                    continue\n",
    "        else: # The data already contains the predictions\n",
    "            sentence = row['Sentence']\n",
    "            prediction = (row['Subject'], row['Relation'], row['Object'])\n",
    "\n",
    "            if prediction[1] in faro_classes:\n",
    "                sentence_uri = node_creation('', sentence, base_add='/sentence') #Generate the URI for the sentence\n",
    "                graph.add((URIRef(row['URI']), nif.sentence, sentence_uri)) #Link the article to the sentence\n",
    "                graph.add((sentence_uri, RDF.type, nif.Sentence)) #Make the sentence URI of class 'Sentence'\n",
    "                graph.add((sentence_uri, RDF.value, Literal(sentence))) #Set the value of the URI equal to the sentence\n",
    "\n",
    "                subject_uri = node_creation('', prediction[0] + str(sentence_uri), base_add='/subject') #Generate the URI for the subject, for now add the uri of sentence to make it unique\n",
    "                #graph.add((sentence_uri, faro.Relata, subject_uri)) #Add the subject to the sentence\n",
    "                graph.add((sentence_uri, nif.word, subject_uri)) #Add the subject to the sentence\n",
    "                graph.add((subject_uri, RDF.type, faro.Relata)) #Make it of class 'Relata'\n",
    "                graph.add((subject_uri, RDF.value, Literal(prediction[0]))) #Set the value of the subject URI equal to the subject\n",
    "\n",
    "                object_uri = node_creation('', prediction[2] + str(sentence_uri), base_add='/object') #Generate the URI for the object, for now add the uri of sentence to make it unique\n",
    "                #graph.add((sentence_uri, faro.Relata, object_uri)) #Add the object to the sentence\n",
    "                graph.add((sentence_uri, nif.word, object_uri)) #Add the object to the sentence\n",
    "                graph.add((object_uri, RDF.type, faro.Relata)) #Make it of class 'Relata'\n",
    "                graph.add((object_uri, RDF.value, Literal(prediction[2]))) #Set the value of the subject URI equal to the object\n",
    "\n",
    "                graph.add((subject_uri, faro_classes[prediction[1]], object_uri)) #Add relation between NERs\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        for event in ast.literal_eval(row['Event']): #Link the article to the corresponding event\n",
    "            #event_uri = node_creation('', event_name, base_add='/event')\n",
    "            graph.add((URIRef(row['URI']), schema.about, URIRef(event)))\n",
    "            graph.add((URIRef(event), schema.subjectOf, URIRef(row['URI'])))\n",
    "\n",
    "graph.serialize('Data/graphs/final_generated/eag_complete.ttl', format='turtle')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Used for drawing the graph\n",
    "import networkx as nx\n",
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_multidigraph\n",
    "\n",
    "nx_graph = rdflib_to_networkx_multidigraph(graph)\n",
    "pos = nx.spring_layout(nx_graph, scale=2)\n",
    "\n",
    "edge_labels = nx.get_edge_attributes(nx_graph, 'r')\n",
    "nx.draw_networkx_edge_labels(nx_graph, pos, edge_labels=edge_labels)\n",
    "nx.draw(nx_graph, with_labels=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge same entities\n",
    "### Entity coreference resolution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# This code will load the clusters from a text file, and merge the nodes in the cluster together\n",
    "import ast\n",
    "from resources import node_creation\n",
    "import pandas as pd\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "base_path = 'Data/cluster_data/output_all/'\n",
    "cluster_dirs = os.listdir(base_path)\n",
    "cluster_docs = [base_path + dir +'/event_clusters.txt' for dir in cluster_dirs if os.path.isdir(base_path + dir)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [03:39<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of failed mentions: 1863\n",
      "Number of double matches: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Graph identifier=Nc930a7b4451b4f59b3729ad19eb3628d (<class 'rdflib.graph.Graph'>)>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = Graph()\n",
    "graph.parse('Data/graphs/final_generated/eag_complete.ttl')\n",
    "data = pd.read_csv('Data/final_data_with_predictions.csv') #Load the original dataset\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "\n",
    "failed_mentions = 0\n",
    "double_match = 0\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT ?mention\n",
    "WHERE {\n",
    "    ?mention a faro:Relata ;\n",
    "        rdf:value ?value\n",
    "}\"\"\"\n",
    "\n",
    "qres = graph.query(query, initNs={\"faro\": \"https://purl.org/faro/\", \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"})\n",
    "all_mentions = [mention['mention'] for mention in qres.bindings]\n",
    "\n",
    "for doc in tqdm(cluster_docs):\n",
    "\n",
    "    with open(doc) as f: #Open the generated cluster file\n",
    "        cluster_doc = f.readlines()\n",
    "\n",
    "    for cluster in cluster_doc:\n",
    "\n",
    "        if cluster.startswith('['):\n",
    "            cluster = ast.literal_eval(cluster)\n",
    "\n",
    "            if len(cluster) != 1:\n",
    "                prev_mention_uri = None\n",
    "\n",
    "                for i, mention in enumerate(cluster):\n",
    "                    is_subject = False\n",
    "                    is_object = False\n",
    "                    mention_uri = None\n",
    "\n",
    "                    mention = mention.split('_')\n",
    "\n",
    "                    instance = data[(data['URI'] == mention[1]) & (data['Sentence_num'] == int(mention[2]))]\n",
    "                    sentence = instance['Sentence'].values[0]\n",
    "                    sentence_uri = node_creation('', sentence, base_add='/sentence') #Generate the URI for the sentence\n",
    "\n",
    "                    #determine subject or object\n",
    "\n",
    "\n",
    "                    if any(part_mention in instance['Subject'].values[0] for part_mention in mention[0].split()):\n",
    "                        subject_mention_uri = node_creation('',instance['Subject'].values[0]  + str(sentence_uri), base_add='/subject')\n",
    "                        if subject_mention_uri in all_mentions: #Double check it\n",
    "                            is_subject = True\n",
    "\n",
    "\n",
    "                    if any(part_mention in instance['Object'].values[0] for part_mention in mention[0].split()):\n",
    "                        object_mention_uri = node_creation('',instance['Object'].values[0] + str(sentence_uri), base_add='/object')\n",
    "                        if object_mention_uri in all_mentions: #Double check again\n",
    "                            is_object = True\n",
    "\n",
    "\n",
    "                    \"\"\"\n",
    "                    if is_subject and is_object: #Look up in the graph, to see which is correct\n",
    "                        if subject_mention_uri in all_mentions:\n",
    "                            is_object = False\n",
    "                        elif object_mention_uri in all_mentions:\n",
    "                            is_subject = False\n",
    "                    \"\"\"\n",
    "\n",
    "                    if not (is_subject or is_object): #The mention could not be found\n",
    "                        #print(mention[0])\n",
    "                        failed_mentions +=1\n",
    "                        continue\n",
    "\n",
    "                    mention_uri = subject_mention_uri if is_subject else object_mention_uri\n",
    "\n",
    "                    if prev_mention_uri != None:\n",
    "                        if is_subject:\n",
    "                            graph.add((prev_mention_uri, owl.sameAs, subject_mention_uri))\n",
    "                        else:\n",
    "                            graph.add((prev_mention_uri, owl.sameAs, object_mention_uri))\n",
    "\n",
    "                    prev_mention_uri = mention_uri\n",
    "\n",
    "\n",
    "print(f\"Number of failed mentions: {failed_mentions}\\nNumber of double matches: {double_match}\")\n",
    "graph.serialize('Data/graphs/final_generated/eag_complete_merged.ttl', format='turtle')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Select most relevant information from the graph\n",
    "### Lookup the values of the selected nodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdflib.plugins.sparql import prepareQuery\n",
    "from rdflib import Graph, URIRef\n",
    "from resources import uri_validator\n",
    "from owlrl import DeductiveClosure\n",
    "\n",
    "namespaces = {\"faro\": \"https://purl.org/faro/\",\n",
    "              \"sem\": \"http://semanticweb.cs.vu.nl/2009/11/sem/\",\n",
    "              \"rnews\": \"http://iptc.org/std/rNews/2011-10-07#\",\n",
    "              \"nif\": \"http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#\",\n",
    "              \"owl\": \"http://www.w3.org/2002/07/owl#\",\n",
    "              \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "              \"schema\": \"http://schema.org/\"}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "graph.parse(\"Data/graphs/final_generated/eag_complete_merged.ttl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Lookup the values of the selected nodes --- Used when running the graph search model\n",
    "\n",
    "selected_nodes = pd.read_csv('Data/subgraph/5-subgraph.csv', index_col=0)\n",
    "graph = Graph()\n",
    "graph.parse(\"Data/graphs/event_article_graph_complete_merged.ttl\")\n",
    "\n",
    "subj_values = []\n",
    "obj_values = []\n",
    "\n",
    "subj_query = prepareQuery(\"\"\"\n",
    "    SELECT ?subj_value Where{\n",
    "\n",
    "    ?subject rdf:value ?subj_value.\n",
    "\n",
    "    }\n",
    "\"\"\", initNs={\"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"})\n",
    "\n",
    "obj_query = prepareQuery(\"\"\"\n",
    "    SELECT ?obj_value Where{\n",
    "\n",
    "    ?object rdf:value ?obj_value.\n",
    "\n",
    "    }\n",
    "\"\"\", initNs={\"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"})\n",
    "\n",
    "for index, row in selected_nodes.iterrows():\n",
    "\n",
    "\n",
    "    subj_node = URIRef(row['subject'])\n",
    "    obj_node = URIRef(row['object'])\n",
    "\n",
    "    subj_qres = graph.query(subj_query, initBindings={\"subject\": subj_node})\n",
    "    obj_qres = graph.query(obj_query, initBindings={\"object\": obj_node})\n",
    "\n",
    "    if len(subj_qres) != 0:\n",
    "        for row_result in subj_qres:\n",
    "\n",
    "            subj_values.append(row_result[0].value)\n",
    "            break\n",
    "\n",
    "    elif uri_validator(row['subject']) == False:\n",
    "        subj_values.append(row['subject'])\n",
    "\n",
    "    else:\n",
    "        subj_values.append(None)\n",
    "\n",
    "\n",
    "    if len(obj_qres) != 0:\n",
    "        for row_result in obj_qres:\n",
    "\n",
    "            obj_values.append(row_result[0].value)\n",
    "            break\n",
    "\n",
    "    elif uri_validator(row['object']) == False:\n",
    "        obj_values.append(row['object'])\n",
    "\n",
    "    else:\n",
    "        obj_values.append(None)\n",
    "\n",
    "selected_nodes['subject_values'] = subj_values\n",
    "selected_nodes['object_values'] = obj_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              subject  \\\n5           http://www.wikidata.org/entity/Q104045825   \n6           http://www.wikidata.org/entity/Q104045825   \n0   http://kflow.eurecom.fr/subject/9b1d7b1f-39e0-...   \n1   http://kflow.eurecom.fr/subject/29e8115d-fc8d-...   \n1   http://kflow.eurecom.fr/subject/cf5a69f1-0ff3-...   \n..                                                ...   \n0   http://kflow.eurecom.fr/subject/aaeca7f3-7b7e-...   \n1   http://kflow.eurecom.fr/subject/99868c3a-7b42-...   \n1   http://kflow.eurecom.fr/subject/0826e220-fc09-...   \n0   http://kflow.eurecom.fr/subject/9942c216-ec8c-...   \n1   http://kflow.eurecom.fr/subject/d613d251-6048-...   \n\n                                           predicate  \\\n5   http://semanticweb.cs.vu.nl/2009/11/sem/hasPlace   \n6    http://semanticweb.cs.vu.nl/2009/11/sem/hasTime   \n0                       https://purl.org/faro/causes   \n1                      https://purl.org/faro/enables   \n1                       https://purl.org/faro/causes   \n..                                               ...   \n0                      https://purl.org/faro/enables   \n1                       https://purl.org/faro/causes   \n1                       https://purl.org/faro/causes   \n0                       https://purl.org/faro/causes   \n1                       https://purl.org/faro/causes   \n\n                                               object   type_df  iteration  \\\n5   http://kflow.eurecom.fr/e5099279-c6f7-5391-bb8...  outgoing          1   \n6   http://kflow.eurecom.fr/ec3994e5-10f9-54d3-b89...  outgoing          1   \n0   http://kflow.eurecom.fr/object/c192afd0-b701-5...  outgoing          4   \n1   http://kflow.eurecom.fr/object/5e8f6cd0-6a9d-5...   ingoing          4   \n1   http://kflow.eurecom.fr/object/ffe64b81-5469-5...   ingoing          4   \n..                                                ...       ...        ...   \n0   http://kflow.eurecom.fr/object/02929a3c-0808-5...  outgoing          4   \n1   http://kflow.eurecom.fr/object/4006f33c-f4d8-5...   ingoing          4   \n1   http://kflow.eurecom.fr/object/4f5e7558-dca8-5...   ingoing          4   \n0   http://kflow.eurecom.fr/object/91b3f484-743a-5...  outgoing          4   \n1   http://kflow.eurecom.fr/object/6a77df3f-903a-5...   ingoing          4   \n\n                           subject_values              object_values  \n5   2021 Kyrgyz constitutional referendum                 Kyrgyzstan  \n6   2021 Kyrgyz constitutional referendum  2021-01-10 00:00:00+00:00  \n0                    coronavirus pandemic                  dependent  \n1                              referendum                     powers  \n1                                   ready                       work  \n..                                    ...                        ...  \n0                            dictatorship             Vladimir Putin  \n1                                  waited                  criticise  \n1                            reservations                  happiness  \n0                             vote-buying                     crisis  \n1                             cooperation                   telegram  \n\n[96 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>predicate</th>\n      <th>object</th>\n      <th>type_df</th>\n      <th>iteration</th>\n      <th>subject_values</th>\n      <th>object_values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>http://www.wikidata.org/entity/Q104045825</td>\n      <td>http://semanticweb.cs.vu.nl/2009/11/sem/hasPlace</td>\n      <td>http://kflow.eurecom.fr/e5099279-c6f7-5391-bb8...</td>\n      <td>outgoing</td>\n      <td>1</td>\n      <td>2021 Kyrgyz constitutional referendum</td>\n      <td>Kyrgyzstan</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>http://www.wikidata.org/entity/Q104045825</td>\n      <td>http://semanticweb.cs.vu.nl/2009/11/sem/hasTime</td>\n      <td>http://kflow.eurecom.fr/ec3994e5-10f9-54d3-b89...</td>\n      <td>outgoing</td>\n      <td>1</td>\n      <td>2021 Kyrgyz constitutional referendum</td>\n      <td>2021-01-10 00:00:00+00:00</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>http://kflow.eurecom.fr/subject/9b1d7b1f-39e0-...</td>\n      <td>https://purl.org/faro/causes</td>\n      <td>http://kflow.eurecom.fr/object/c192afd0-b701-5...</td>\n      <td>outgoing</td>\n      <td>4</td>\n      <td>coronavirus pandemic</td>\n      <td>dependent</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://kflow.eurecom.fr/subject/29e8115d-fc8d-...</td>\n      <td>https://purl.org/faro/enables</td>\n      <td>http://kflow.eurecom.fr/object/5e8f6cd0-6a9d-5...</td>\n      <td>ingoing</td>\n      <td>4</td>\n      <td>referendum</td>\n      <td>powers</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://kflow.eurecom.fr/subject/cf5a69f1-0ff3-...</td>\n      <td>https://purl.org/faro/causes</td>\n      <td>http://kflow.eurecom.fr/object/ffe64b81-5469-5...</td>\n      <td>ingoing</td>\n      <td>4</td>\n      <td>ready</td>\n      <td>work</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>http://kflow.eurecom.fr/subject/aaeca7f3-7b7e-...</td>\n      <td>https://purl.org/faro/enables</td>\n      <td>http://kflow.eurecom.fr/object/02929a3c-0808-5...</td>\n      <td>outgoing</td>\n      <td>4</td>\n      <td>dictatorship</td>\n      <td>Vladimir Putin</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://kflow.eurecom.fr/subject/99868c3a-7b42-...</td>\n      <td>https://purl.org/faro/causes</td>\n      <td>http://kflow.eurecom.fr/object/4006f33c-f4d8-5...</td>\n      <td>ingoing</td>\n      <td>4</td>\n      <td>waited</td>\n      <td>criticise</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://kflow.eurecom.fr/subject/0826e220-fc09-...</td>\n      <td>https://purl.org/faro/causes</td>\n      <td>http://kflow.eurecom.fr/object/4f5e7558-dca8-5...</td>\n      <td>ingoing</td>\n      <td>4</td>\n      <td>reservations</td>\n      <td>happiness</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>http://kflow.eurecom.fr/subject/9942c216-ec8c-...</td>\n      <td>https://purl.org/faro/causes</td>\n      <td>http://kflow.eurecom.fr/object/91b3f484-743a-5...</td>\n      <td>outgoing</td>\n      <td>4</td>\n      <td>vote-buying</td>\n      <td>crisis</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://kflow.eurecom.fr/subject/d613d251-6048-...</td>\n      <td>https://purl.org/faro/causes</td>\n      <td>http://kflow.eurecom.fr/object/6a77df3f-903a-5...</td>\n      <td>ingoing</td>\n      <td>4</td>\n      <td>cooperation</td>\n      <td>telegram</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_nodes = selected_nodes[~selected_nodes['predicate'].isin(['http://schema.org/subjectOf', 'http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#word'])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Query the graph: extract triples without using graph search algorithm\n",
    "## Extract: time, place, actor, contentLocation, contentReferenceTime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<Graph identifier=N9798bffa0cc344e9bf3d76a3bb1e2319 (<class 'rdflib.graph.Graph'>)>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = Graph()\n",
    "graph.parse(\"Data/graphs/final_generated/eag_complete_merged.ttl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Extract 4W's from a event\n",
    "from collections import defaultdict\n",
    "query = \"\"\"\n",
    "SELECT ?time ?place ?actor ?beginTime ?endTime ?timeStamp where {\n",
    "\t?event a  sem:Event.\n",
    "    OPTIONAL{?event sem:hasTime ?time}.\n",
    "    OPTIONAL{?event sem:hasPlace ?place}.\n",
    "    OPTIONAL{?event sem:hasActor ?actor}.\n",
    "    OPTIONAL{?event sem:hasBeginTimeStamp ?beginTime}\n",
    "    OPTIONAL{?event sem:hasEndTimeStamp ?endTime}\n",
    "    OPTIONAL{?event sem:hasTimeStamp ?timeStamp}\n",
    "}\"\"\"\n",
    "\n",
    "#event = URIRef(\"http://www.wikidata.org/entity/Q102850603\")\n",
    "event = URIRef(\"http://www.wikidata.org/entity/Q104218016\")\n",
    "\n",
    "qres = graph.query(query, initNs= namespaces, initBindings={\"event\": event})\n",
    "four_W = {}\n",
    "\n",
    "for row in qres.bindings:\n",
    "    for key in row.keys():\n",
    "        if key not in four_W.keys():\n",
    "            four_W[key] = [row[key]]\n",
    "        else:\n",
    "            if row[key] not in four_W[key]:\n",
    "                four_W[key].append(row[key])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT (COUNT(?i) as ?num_input) WHERE {\n",
    "    ?i ?p2 ?uri\n",
    "} GROUP BY ?uri\n",
    "\"\"\"\n",
    "\n",
    "four_W_scores = {}\n",
    "for values in four_W.values():\n",
    "    for value in values:\n",
    "        qres = graph.query(query, initNs= namespaces, initBindings={\"uri\": value})\n",
    "        four_W_scores[value] = int(qres.bindings[0]['num_input'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time - [rdflib.term.URIRef('http://kflow.eurecom.fr/a74f5b97-eeac-5738-98b9-cfe2ef45cc0c')]\n",
      "place - [rdflib.term.URIRef('http://kflow.eurecom.fr/94391869-ec3a-5944-b903-d73d58856a8b')]\n",
      "beginTime - [rdflib.term.URIRef('http://kflow.eurecom.fr/a9acd41b-8395-5fce-9a5a-56a4fc751603')]\n",
      "endTime - [rdflib.term.URIRef('http://kflow.eurecom.fr/579ef621-55b4-55bd-acb0-6c1fbc06e74e')]\n"
     ]
    }
   ],
   "source": [
    "for key, value in four_W.items():\n",
    "    print(f\"{key} - {value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{rdflib.term.URIRef('http://kflow.eurecom.fr/a74f5b97-eeac-5738-98b9-cfe2ef45cc0c'): 8,\n rdflib.term.URIRef('http://kflow.eurecom.fr/94391869-ec3a-5944-b903-d73d58856a8b'): 15,\n rdflib.term.URIRef('http://kflow.eurecom.fr/a9acd41b-8395-5fce-9a5a-56a4fc751603'): 1,\n rdflib.term.URIRef('http://kflow.eurecom.fr/579ef621-55b4-55bd-acb0-6c1fbc06e74e'): 1}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_W_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from owlrl import OWLRL_Semantics #This is needed to allow owl reasoning over the sameAs links\n",
    "DeductiveClosure(OWLRL_Semantics).expand(graph)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#First, extract all the mentions from the sentences\n",
    "query = \"\"\"\n",
    "PREFIX faro: <https://purl.org/faro/>\n",
    "PREFIX sem: <http://semanticweb.cs.vu.nl/2009/11/sem/>\n",
    "PREFIX rnews: <http://iptc.org/std/rNews/2011-10-07#>\n",
    "PREFIX nif: <http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "prefix schema: <http://schema.org/>\n",
    "select distinct ?mention where {\n",
    "\t?event a sem:Event;\n",
    "         schema:subjectOf ?article.\n",
    "    ?article nif:sentence ?sentence.\n",
    "    ?sentence nif:word ?mention.\n",
    "    ?mention owl:sameAs ?o .\n",
    "\n",
    "}\"\"\"\n",
    "#event = URIRef(\"http://www.wikidata.org/entity/Q102850603\")\n",
    "event = URIRef(\"http://www.wikidata.org/entity/Q104218016\")\n",
    "qres = graph.query(query, initNs= namespaces, initBindings={\"event\": event})\n",
    "mentions = [mention[0] for mention in qres] #Save all mentions of this event"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "#Now, find the biggest cluster\n",
    "query = \"\"\"\n",
    "SELECT ?nodes where {\n",
    "\t?mention a faro:Relata;\n",
    "\t    owl:sameAs+ ?nodes\n",
    "}\n",
    "\"\"\"\n",
    "clusters = {} #the key will be one of the mentions in the set\n",
    "for mention in mentions:\n",
    "    mention = URIRef(mention)\n",
    "    qres = graph.query(query, initNs= namespaces, initBindings={\"mention\": mention})\n",
    "    mention_cluster = set()\n",
    "    for result in qres:\n",
    "        mention_cluster.add(result[0])\n",
    "    if not any(key in mention_cluster for key in clusters.keys()) and len(mention_cluster)!=1: #Only keep unique clusters, keep as key one of the elements in the cluster\n",
    "        clusters[mention] = mention_cluster\n",
    "clusters= dict(sorted(clusters.items(), key=lambda x:len(x[1]), reverse=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandemic\n",
      "pandemic\n",
      "coronavirus pandemic\n",
      "Covid-19 pandemic\n",
      "pandemic\n",
      "\n",
      "\n",
      "awards\n",
      "Golden Globe Awards\n",
      "awards\n",
      "awards\n",
      "\n",
      "\n",
      "whittled\n",
      "whittled\n",
      "whittling\n",
      "whittles\n",
      "\n",
      "\n",
      "unveiling\n",
      "unveiling\n",
      "unveiling\n",
      "unveiling\n",
      "\n",
      "\n",
      "NETFLIX\n",
      "Netflix\n",
      "NETFLIX\n",
      "NETFLIX\n",
      "\n",
      "\n",
      "Disney+\n",
      "Disney+\n",
      "Nomadland\n",
      "\n",
      "\n",
      "nominations\n",
      "nominations\n",
      "nominations\n",
      "\n",
      "\n",
      "acronym\n",
      "acronym\n",
      "acronym\n",
      "\n",
      "\n",
      "recognition\n",
      "recognition\n",
      "recognition\n",
      "\n",
      "\n",
      "delayed\n",
      "delayed\n",
      "\n",
      "\n",
      "music\n",
      "Music\n",
      "\n",
      "\n",
      "published\n",
      "published\n",
      "\n",
      "\n",
      "streaming\n",
      "streaming\n",
      "\n",
      "\n",
      "season\n",
      "season\n",
      "\n",
      "\n",
      "mockumentary\n",
      "mockumentary\n",
      "\n",
      "\n",
      "communicate\n",
      "communicate\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find the text values for the clusters\n",
    "query = \"\"\"\n",
    "SELECT ?value where {\n",
    "\t?mention a faro:Relata;\n",
    "\t    rdf:value ?value\n",
    "}\"\"\"\n",
    "for cluster in clusters.values():\n",
    "    for mention in cluster:\n",
    "        qres = graph.query(query, initNs= namespaces, initBindings={\"mention\": mention})\n",
    "        print(qres.bindings[0]['value'])\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "data": {
      "text/plain": "{rdflib.term.URIRef('http://kflow.eurecom.fr/subject/2dd6ba95-3734-59b0-9528-3de2c21dc03f'): {rdflib.term.URIRef('http://kflow.eurecom.fr/subject/12eae3c7-d526-546c-91ff-c5ef982a41c4'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/27731041-85f0-56e1-a4c5-6cb7dd460921'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/2dd6ba95-3734-59b0-9528-3de2c21dc03f'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/4c395911-5b24-5da9-a3e1-42ad49701b4a'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/ad1cd32d-858e-5fb3-8c50-2922ef4af5cd')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/subject/9809b531-8b70-550b-984b-c778b81f8d86'): {rdflib.term.URIRef('http://kflow.eurecom.fr/object/76b8a5f7-228e-5a38-9df6-d51953381da1'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/object/b2423252-58d2-5011-96c2-c59cb5271547'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/88ef6acd-f336-5f26-a7bc-d5a83e52803b'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/9809b531-8b70-550b-984b-c778b81f8d86')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/object/266297a5-9289-5466-b72e-71e34a8e70c8'): {rdflib.term.URIRef('http://kflow.eurecom.fr/object/266297a5-9289-5466-b72e-71e34a8e70c8'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/object/48a89054-dc38-56dc-8a57-82b37b5cab25'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/object/a7ad4de1-5412-579f-8923-2a32a74ae3e1'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/object/eb51e296-874e-5411-8bee-f10015fc12c8')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/subject/5f36a824-5519-54db-8c14-f5449978d1ec'): {rdflib.term.URIRef('http://kflow.eurecom.fr/subject/172cf324-d218-535c-9767-fbcc9f770824'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/5f36a824-5519-54db-8c14-f5449978d1ec'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/bebe4669-fc09-517d-85b6-2ba217aaf5b7'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/c41942b4-49ad-50da-a1f5-6b26a4d13eff')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/object/4ae6edf3-aea5-53b7-a087-7ec6f20b8c80'): {rdflib.term.URIRef('http://kflow.eurecom.fr/object/4ae6edf3-aea5-53b7-a087-7ec6f20b8c80'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/object/670edd91-8a30-5327-816e-d0f802ee9264'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/63d8c4a9-08dc-5b4a-999b-b7cb2c59a72e'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/c3c65e2c-97a5-54bf-a429-d544f33d1471')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/object/44bde44f-2b9b-5de7-b461-2646780e654f'): {rdflib.term.URIRef('http://kflow.eurecom.fr/object/44bde44f-2b9b-5de7-b461-2646780e654f'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/object/ec35873b-4f9d-5c3a-917b-06ee8185f0ac'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/1fb965eb-01fe-5fb1-8b52-50930eda28b1')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/subject/37b4ce5b-f5e8-532a-b69e-13e4cbde8f7c'): {rdflib.term.URIRef('http://kflow.eurecom.fr/subject/37b4ce5b-f5e8-532a-b69e-13e4cbde8f7c'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/877edd86-e069-5ca7-9dc5-833268571bfd'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/ea6fa2f4-bea2-538d-b756-8aff2d19ff0f')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/subject/dd563c42-2125-55db-882e-1c8f8a1dd634'): {rdflib.term.URIRef('http://kflow.eurecom.fr/subject/01f997bd-df9e-583c-82c1-d1732c2cf006'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/dd563c42-2125-55db-882e-1c8f8a1dd634'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/de7b49d9-2fb8-5638-b1ae-391a9a9cf507')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/object/1b1d71d8-e8e6-57c5-86e9-c2d22d473d17'): {rdflib.term.URIRef('http://kflow.eurecom.fr/object/1b1d71d8-e8e6-57c5-86e9-c2d22d473d17'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/object/333e47e3-5328-5a84-9506-f091e4864d03'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/object/5c6ef2c9-5088-5d4c-bd25-802c5c4abb99')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/object/7a3db666-04d4-567c-8dae-2221f323131f'): {rdflib.term.URIRef('http://kflow.eurecom.fr/object/7a3db666-04d4-567c-8dae-2221f323131f'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/object/c6ff28d5-a564-5c0c-902f-eb91bcef59a5')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/object/0bb2f4cd-2f59-5499-ae53-39f564e333bf'): {rdflib.term.URIRef('http://kflow.eurecom.fr/object/0bb2f4cd-2f59-5499-ae53-39f564e333bf'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/3cd0436b-072a-58c3-90da-652d2cd04d69')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/subject/7ba7c022-bcbd-5d69-b6df-009bc64ed144'): {rdflib.term.URIRef('http://kflow.eurecom.fr/object/6b378897-647a-5253-b608-60d91556d024'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/7ba7c022-bcbd-5d69-b6df-009bc64ed144')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/subject/22166768-87dc-5322-aab3-fd884191209e'): {rdflib.term.URIRef('http://kflow.eurecom.fr/object/d3d003fe-f32a-5dd3-a63c-df6029102115'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/22166768-87dc-5322-aab3-fd884191209e')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/subject/334739d7-1436-5a70-82c8-d46d5f494554'): {rdflib.term.URIRef('http://kflow.eurecom.fr/subject/19ea29be-9923-507e-be61-704d292c9cab'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/334739d7-1436-5a70-82c8-d46d5f494554')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/subject/a9f197cd-d3cc-521d-a27d-4f03a6ede02c'): {rdflib.term.URIRef('http://kflow.eurecom.fr/subject/64a816b9-25f0-5c9a-a4e3-b9913bfb9c66'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/subject/a9f197cd-d3cc-521d-a27d-4f03a6ede02c')},\n rdflib.term.URIRef('http://kflow.eurecom.fr/object/e1496324-c3c5-596c-bd06-7b6cad73692d'): {rdflib.term.URIRef('http://kflow.eurecom.fr/object/65aa5989-7456-5b54-8648-28b1bdbaa8c1'),\n  rdflib.term.URIRef('http://kflow.eurecom.fr/object/e1496324-c3c5-596c-bd06-7b6cad73692d')}}"
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating the correct format for JointGT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1800 instances\n",
      "Processed 201 instances\n",
      "Processed 95 instances\n"
     ]
    }
   ],
   "source": [
    "#Now convert rebel relationship data to JointGT input format\n",
    "from resources import gen_jointgt_input_format, gen_mapping_dict\n",
    "\n",
    "encoding_dict, total_instances = gen_mapping_dict('..\\\\JointGT\\\\JointGT_data\\\\data\\\\webnlg\\\\train.json', '..\\\\JointGT\\\\JointGT_data\\\\data\\\\webnlg\\\\val.json', '..\\\\JointGT\\\\JointGT_data\\\\data\\\\webnlg\\\\test.json')\n",
    "\n",
    "relation_data_train = pd.read_csv('Data/rebel_v2/data/new_split/train.csv', index_col=0)\n",
    "relation_data_val = pd.read_csv('Data/rebel_v2/data/new_split/val.csv', index_col=0)\n",
    "relation_data_test = pd.read_csv('Data/rebel_v2/data/new_split/test.csv', index_col=0)\n",
    "\n",
    "total_instances += gen_jointgt_input_format(relation_data_train, 'Data/jointGT/faro/relation_dataset_jointgt_train.json', encoding_dict, 'trigger1', 'label', 'trigger2', 'sentence', single_event= False, start_id=total_instances)\n",
    "total_instances += gen_jointgt_input_format(relation_data_val, 'Data/jointGT/faro/relation_dataset_jointgt_val.json', encoding_dict, 'trigger1', 'label', 'trigger2', 'sentence', single_event= False, start_id= total_instances)\n",
    "total_instances += gen_jointgt_input_format(relation_data_test, 'Data/jointGT/faro/relation_dataset_jointgt_test.json', encoding_dict, 'trigger1', 'label', 'trigger2', 'sentence', single_event= False, start_id= total_instances)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#Next step: Combine both the original WebNLG data with the newly generated one\n",
    "import random\n",
    "def combine_datasets(dataset1, dataset2, output_file):\n",
    "    dataset1 = json.load(open(dataset1))\n",
    "    dataset2 = json.load(open(dataset2))\n",
    "\n",
    "    combined = dataset1+dataset2\n",
    "    random.shuffle(combined)\n",
    "\n",
    "    with open(output_file, \"w\") as json_out:\n",
    "        json.dump(combined, json_out, indent = 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "combine_datasets('Data\\\\jointGT\\\\faro\\\\relation_dataset_jointgt_train.json', '..\\\\JointGT\\\\JointGT_data\\\\data\\\\webnlg\\\\train.json', 'Data\\\\jointGT\\\\combined\\\\train.json')\n",
    "combine_datasets('Data\\\\jointGT\\\\faro\\\\relation_dataset_jointgt_val.json', '..\\\\JointGT\\\\JointGT_data\\\\data\\\\webnlg\\\\val.json', 'Data\\\\jointGT\\\\combined\\\\val.json')\n",
    "combine_datasets('Data\\\\jointGT\\\\faro\\\\relation_dataset_jointgt_test.json', '..\\\\JointGT\\\\JointGT_data\\\\data\\\\webnlg\\\\test.json', 'Data\\\\jointGT\\\\combined\\\\test.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 52 instances\n"
     ]
    }
   ],
   "source": [
    "## Take the retrieved triples, and generate an input format for JointGT\n",
    "#For now just create the triples by hand\n",
    "#Changed 1 \"pandemic\" to \"Covid-19 pandemic\"\n",
    "import pandas as pd\n",
    "from resources import gen_jointgt_input_format_multiple\n",
    "\n",
    "tuples1 = ((\"2021 Sundance Film Festival\", \"hasTime\", \"2021-01-01\", 0), (\"2021 Sundance Film Festival\", \"hasPlace\", \"United States of America\", 0),\n",
    "(\"2021 Sundance Film Festival\", \"beginTime\", \"2021-01-28\", 0), (\"2021 Sundance Film Festival\", \"endTime\", \"2021-02-03\", 0),\n",
    "(\"Covid-19 pandemic\", \"cause\", \"online streaming\", 0), (\"Covid-19 pandemic\", \"cause\", \"delayed\", 0), (\"stunt workers\", \"enable\", \"recognition\", 0),\n",
    "\n",
    "(\"Covid-19 pandemic\", \"cause\", \"online streaming\", 1), (\"Covid-19 pandemic\", \"cause\", \"delayed\", 1), (\"stunt workers\", \"enable\", \"recognition\", 1),\n",
    "(\"Covid-19 pandemic\", \"started\", \"2020\", 1),\n",
    "\n",
    "(\"2021 Sundance Film Festival\", \"took place\", \"United States of America\", 2),\n",
    "(\"2021 Sundance Film Festival\", \"begin time\", \"2021-01-28\", 2), (\"2021 Sundance Film Festival\", \"end time\", \"2021-02-03\", 2),\n",
    "(\"Covid-19 pandemic\", \"enable\", \"more online streaming\", 2), ('more online streaming', 'cause', 'more viewers', 2),\n",
    "\n",
    "(\"2021 Sundance Film Festival\", \"took place\", \"United States of America\", 3),\n",
    "(\"Covid-19 pandemic\", \"has enabled\", \"more online streaming\", 3), ('more online streaming', 'has caused', 'more viewers', 3),\n",
    "\n",
    "(\"2021 Sundance Film Festival\", \"place\", \"United States of America\", 4),\n",
    "(\"2021 Sundance Film Festival\", \"start\", \"2021-01-28\", 4), (\"2021 Sundance Film Festival\", \"end\", \"2021-02-03\", 4),\n",
    "(\"Covid-19 pandemic\", \"enable\", \"more online streaming\", 4), ('more online streaming', 'cause', 'more viewers', 4),\n",
    "\n",
    "(\"2021 Sundance Film Festival\", \"place\", \"United States of America\", 5),\n",
    "(\"2021 Sundance Film Festival\", \"started\", \"2021-01-28\", 5), (\"2021 Sundance Film Festival\", \"ended\", \"2021-02-03\", 5),\n",
    "(\"Covid-19 pandemic\", \"enable\", \"more online streaming\", 5), ('more online streaming', 'cause', 'more viewers', 5),\n",
    "\n",
    "(\"high temperature\", \"enable\", \"increased ice cream sales\", 6), (\"hot weather\", \"cause\", \"high temperature\", 6), (\"high temperature\", \"prevent\", \"going out\", 6),\n",
    "\n",
    "(\"2021 Sundance Film Festival\", \"place\", \"United States of America\", 7),\n",
    "(\"2021 Sundance Film Festival\", \"start\", \"2021-01-28\", 7), (\"2021 Sundance Film Festival\", \"end\", \"2021-02-03\", 7),\n",
    "(\"Covid-19 pandemic\", \"has enabled\", \"more online streaming\", 7), ('more online streaming', 'has caused', 'more viewers', 7),\n",
    "\n",
    "(\"2021 Sundance Film Festival\", \"took place\", \"United States of America\", 8),\n",
    "(\"2021 Sundance Film Festival\", \"begin time\", \"2021-01-28\", 8),\n",
    "(\"more online streaming\", \"enable\", \"Covid-19 pandemic\", 8), ('more viewers', 'cause', 'more online streaming', 8),\n",
    "\n",
    "(\"pandemic\", \"has caused\", \"deaths\", 9), (\"deaths\", \"has caused\", \"lockdown\", 9), (\"lockdown\", \"has intention\", \"decreasing infections\", 9),\n",
    "(\"pandemic\", \"has enabled\", \"vaccine\", 9),\n",
    "\n",
    "(\"Sundance Film Festival\", \"place\", \"United States of America\", 10), (\"Sundance Film Festival\", \"has enabled\", \"mutliple awards\", 10),\n",
    " (\"Covid-19 pandemic\", \"delayed\", \"Sundance Film Festival\", 10),\n",
    "\n",
    "(\"Sundance Film Festival\", \"place\", \"United States of America\", 11), (\"Sundance Film Festival\", \"has enabled\", \"mutliple awards\", 11),\n",
    " (\"Covid-19 pandemic\", \"delayed\", \"Sundance Film Festival\", 11), (\"Covid-19 pandemic\", \"has enabled\", \"online streaming\", 11)\n",
    ")\n",
    "\n",
    "\n",
    "created_dataset = pd.DataFrame(tuples1, columns =['subject_values', 'predicate', 'object_values', 'instance'])\n",
    "\n",
    "total_instances = gen_jointgt_input_format_multiple(created_dataset, 'Data/jointGT/generated_for_test/test5.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "gen_jointgt_input_format_multiple(data, output_file, encoding_dict= None, subj_col= 'subject_values', rel_col= 'predicate', obj_col= 'object_values', sent_col = None, inst_col = 'instance')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}